{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b09b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import psycopg2\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a28b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Job_Duration  Data_Volume  Nbr_Components\n",
      "0             33447        39387               9\n",
      "1             33447        39600               9\n",
      "2             33447        39593               9\n",
      "3             33447        39680               9\n",
      "4             33447        41401               9\n",
      "...             ...          ...             ...\n",
      "11843         20993         3553               5\n",
      "11844         20993         3554               5\n",
      "11845         20993         3512               5\n",
      "11846         20993         3482               5\n",
      "11847         20993         3458               5\n",
      "\n",
      "[11848 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Establish a connection to the database\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"ProjetBI\",\n",
    "    user=\"postgres\",\n",
    "    password=\"marwa\"\n",
    ")\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute the SQL query\n",
    "cur.execute(\"SELECT stats.\\\"Job_Duration\\\", stats.\\\"Data_Volume\\\", (select count(\\\"Component_PK\\\") from public.\\\"DimJob\\\" join public.\\\"DimComponent\\\" on(public.\\\"DimJob\\\".\\\"Job_PK\\\" = public.\\\"DimComponent\\\".\\\"Job_FK\\\") where \\\"Job_PK\\\"=stats.\\\"Job_FK\\\" group by \\\"Job_Code\\\") as \\\"Nbr_Components\\\" FROM public.\\\"FactStats\\\" stats\")\n",
    "# Fetch all the rows as a list of tuples\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Convert the list of tuples to a pandas DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"Job_Duration\",\"Data_Volume\", \"Nbr_Components\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3a4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Job_Duration  Data_Volume  Nbr_Components\n",
      "0          1.000000     0.388254        1.000000\n",
      "1          1.000000     0.390353        1.000000\n",
      "2          1.000000     0.390284        1.000000\n",
      "3          1.000000     0.391142        1.000000\n",
      "4          1.000000     0.408107        1.000000\n",
      "...             ...          ...             ...\n",
      "11843      0.199666     0.035014        0.333333\n",
      "11844      0.199666     0.035024        0.333333\n",
      "11845      0.199666     0.034610        0.333333\n",
      "11846      0.199666     0.034314        0.333333\n",
      "11847      0.199666     0.034078        0.333333\n",
      "\n",
      "[11848 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1030ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test division\n",
    "X2 = df.iloc[:,:-1]\n",
    "y2 = df.iloc[:,-1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8190fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisation et entrainement du modèle\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "rf_model.fit(X_train2, y_train2)\n",
    "\n",
    "#Test\n",
    "y_pred2 = rf_model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ff1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² :  0.9999375873454279\n",
      "MSE: 4.128770120331218e-06\n"
     ]
    }
   ],
   "source": [
    "#R²\n",
    "r2_random_forest = r2_score(y_test2, y_pred2)\n",
    "print(\"R² : \",r2_random_forest)\n",
    "mse = mean_squared_error(y_test2, y_pred2)\n",
    "print(\"MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
